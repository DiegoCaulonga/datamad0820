{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.77911033]\n",
      " [21.26848215]\n",
      " [27.45756011]\n",
      " [23.99983782]\n",
      " [16.84967626]\n",
      " [23.29783333]\n",
      " [ 3.56877738]\n",
      " [30.33936942]\n",
      " [19.36193355]\n",
      " [28.97734705]\n",
      " [26.91928429]\n",
      " [37.89324371]\n",
      " [29.07711231]\n",
      " [12.37109681]\n",
      " [ 8.79493864]\n",
      " [19.13828242]\n",
      " [10.63109137]\n",
      " [25.30705923]\n",
      " [22.43244719]\n",
      " [13.42361526]\n",
      " [39.3526132 ]\n",
      " [31.49078026]\n",
      " [27.51942583]\n",
      " [41.49034418]\n",
      " [11.79515497]\n",
      " [31.33664986]\n",
      " [20.16282222]\n",
      " [26.21869411]\n",
      " [20.56606924]\n",
      " [23.24809611]\n",
      " [35.16763659]\n",
      " [22.00295599]\n",
      " [ 6.60990256]\n",
      " [18.23897703]\n",
      " [20.47091797]\n",
      " [18.15862497]\n",
      " [27.57055752]\n",
      " [14.78550019]\n",
      " [ 2.04074871]\n",
      " [32.04388286]\n",
      " [17.16948861]\n",
      " [33.27199749]\n",
      " [24.58040056]\n",
      " [21.13885704]\n",
      " [31.39275108]\n",
      " [28.35774468]\n",
      " [26.58310351]\n",
      " [23.60592931]\n",
      " [25.32167516]\n",
      " [26.22024531]\n",
      " [13.11734233]\n",
      " [23.36654079]\n",
      " [26.79249727]\n",
      " [19.86040159]\n",
      " [21.39987106]\n",
      " [25.99886811]\n",
      " [15.58996945]\n",
      " [31.23587395]\n",
      " [15.96927377]\n",
      " [31.05136995]\n",
      " [21.40020827]\n",
      " [44.82099715]\n",
      " [12.95857512]\n",
      " [34.38111912]\n",
      " [13.06083189]\n",
      " [26.8870322 ]\n",
      " [28.80603456]\n",
      " [41.17248336]\n",
      " [18.22592002]\n",
      " [16.60164616]\n",
      " [17.57888399]\n",
      " [16.05952637]\n",
      " [21.52604328]\n",
      " [16.35019735]\n",
      " [23.47538836]\n",
      " [23.02965247]\n",
      " [ 5.31850957]\n",
      " [20.76733413]\n",
      " [11.21690683]\n",
      " [ 5.97689503]\n",
      " [19.13609811]\n",
      " [24.87107589]\n",
      " [11.24736479]\n",
      " [45.64109877]\n",
      " [43.84587968]\n",
      " [21.08821222]\n",
      " [36.30451186]\n",
      " [19.02397283]\n",
      " [17.58531713]\n",
      " [19.71990523]\n",
      " [24.83325614]\n",
      " [22.87894041]\n",
      " [28.54411379]\n",
      " [16.10195843]\n",
      " [31.795606  ]\n",
      " [25.34233323]\n",
      " [25.60358511]\n",
      " [12.21312967]\n",
      " [33.30951482]\n",
      " [28.38752544]\n",
      " [18.28211576]\n",
      " [37.08653326]\n",
      " [27.13198519]\n",
      " [17.99578793]\n",
      " [21.43878838]\n",
      " [34.21162863]\n",
      " [30.71212202]\n",
      " [26.86161771]\n",
      " [14.00917411]\n",
      " [15.24881895]\n",
      " [21.64396252]\n",
      " [25.42016397]\n",
      " [13.15996539]\n",
      " [31.1134449 ]\n",
      " [13.70341414]\n",
      " [19.12528683]\n",
      " [24.22538062]\n",
      " [19.50802539]\n",
      " [22.44908745]\n",
      " [18.03988528]\n",
      " [18.12725544]\n",
      " [21.21767828]\n",
      " [28.65236429]\n",
      " [ 8.38841588]\n",
      " [24.96945148]\n",
      " [27.14929594]\n",
      " [20.87891957]\n",
      " [23.04144634]\n",
      " [24.15545617]\n",
      " [24.84750214]\n",
      " [20.89079236]\n",
      " [18.89070305]\n",
      " [24.10936144]\n",
      " [28.86828121]\n",
      " [15.62673533]\n",
      " [24.12067141]\n",
      " [20.14545871]\n",
      " [ 7.74617722]\n",
      " [39.26379643]\n",
      " [24.18018912]\n",
      " [13.50369139]\n",
      " [20.66331846]\n",
      " [23.81700522]\n",
      " [23.86421795]\n",
      " [23.46482826]\n",
      " [37.88234241]\n",
      " [18.82850969]\n",
      " [36.7345726 ]\n",
      " [-0.52324275]\n",
      " [23.63721588]\n",
      " [24.27544827]\n",
      " [19.31830709]\n",
      " [21.5009646 ]\n",
      " [21.18999427]\n",
      " [23.00723143]\n",
      " [16.61742175]\n",
      " [21.58944304]\n",
      " [34.08893958]\n",
      " [17.38337592]\n",
      " [20.92975608]\n",
      " [29.98195925]\n",
      " [23.1179732 ]\n",
      " [20.18039455]\n",
      " [23.81895666]\n",
      " [15.75194745]\n",
      " [12.5167954 ]\n",
      " [39.71481314]\n",
      " [12.91161582]\n",
      " [17.49105854]\n",
      " [17.64614762]\n",
      " [31.47760559]\n",
      " [18.42838387]\n",
      " [ 9.20033698]\n",
      " [23.54820541]\n",
      " [28.96834791]\n",
      " [27.01894263]\n",
      " [33.95043614]\n",
      " [17.4801997 ]\n",
      " [23.48653535]\n",
      " [21.64519761]\n",
      " [19.7909349 ]\n",
      " [42.33100856]\n",
      " [22.65494357]\n",
      " [13.1487658 ]\n",
      " [23.45469529]\n",
      " [14.00203169]\n",
      " [26.88285635]\n",
      " [ 8.55572161]\n",
      " [19.75056565]\n",
      " [24.68786025]\n",
      " [15.81377686]\n",
      " [19.75907248]\n",
      " [24.22277125]\n",
      " [22.40749811]\n",
      " [30.1336304 ]\n",
      " [23.89322347]\n",
      " [31.06954889]\n",
      " [23.88686899]\n",
      " [16.46313573]\n",
      " [32.65031115]\n",
      " [20.41869938]\n",
      " [27.9179109 ]\n",
      " [12.2147812 ]\n",
      " [23.08695058]\n",
      " [34.81717142]\n",
      " [29.05703366]\n",
      " [26.15921059]\n",
      " [27.89363056]\n",
      " [20.28356838]\n",
      " [30.52442732]\n",
      " [35.03948323]\n",
      " [22.34433284]\n",
      " [33.47270446]\n",
      " [28.36692308]\n",
      " [16.3291378 ]\n",
      " [14.25767129]\n",
      " [20.24027906]\n",
      " [22.06054922]\n",
      " [20.56104407]\n",
      " [20.89602144]\n",
      " [35.29280314]\n",
      " [26.46930259]\n",
      " [22.29785063]\n",
      " [15.3878051 ]\n",
      " [33.14379893]\n",
      " [22.42401   ]\n",
      " [20.07910947]\n",
      " [ 6.82588463]\n",
      " [15.22377497]\n",
      " [21.77759974]\n",
      " [12.90123216]\n",
      " [39.38447374]\n",
      " [12.64216578]\n",
      " [20.40563049]\n",
      " [18.72439961]\n",
      " [13.13361184]\n",
      " [25.50171931]\n",
      " [ 4.26229034]\n",
      " [24.73416302]\n",
      " [18.22741817]\n",
      " [22.59349108]\n",
      " [10.98764523]\n",
      " [20.14571606]\n",
      " [27.20249257]\n",
      " [38.23445934]\n",
      " [14.05809297]\n",
      " [33.45590255]\n",
      " [17.48378146]\n",
      " [ 3.66460911]\n",
      " [26.80253771]\n",
      " [25.77252551]\n",
      " [24.5117834 ]\n",
      " [21.76593015]\n",
      " [21.9680624 ]\n",
      " [18.26938708]\n",
      " [ 6.0996187 ]\n",
      " [25.74160809]\n",
      " [20.64029486]\n",
      " [21.41869094]\n",
      " [18.59584334]\n",
      " [20.40463736]\n",
      " [25.06094972]\n",
      " [22.60198916]\n",
      " [23.05144549]\n",
      " [17.20989733]\n",
      " [20.88413048]\n",
      " [19.63233546]\n",
      " [19.86292362]\n",
      " [16.67691019]\n",
      " [19.35619224]\n",
      " [32.18102437]\n",
      " [23.57500951]\n",
      " [19.55575222]\n",
      " [28.7859301 ]\n",
      " [24.9283159 ]\n",
      " [28.43299642]\n",
      " [20.09657672]\n",
      " [30.20839152]\n",
      " [12.14995167]\n",
      " [16.27148954]\n",
      " [21.15698419]\n",
      " [14.09858381]\n",
      " [12.02572383]\n",
      " [25.16688171]\n",
      " [12.27956171]\n",
      " [ 8.42136993]\n",
      " [35.29429693]\n",
      " [25.27238191]\n",
      " [20.42689135]\n",
      " [24.37667106]\n",
      " [20.22124285]\n",
      " [17.18486062]\n",
      " [22.51203661]\n",
      " [13.30799062]\n",
      " [24.66004591]\n",
      " [16.98145552]\n",
      " [22.08776409]\n",
      " [16.24616625]\n",
      " [11.42553639]\n",
      " [27.1137734 ]\n",
      " [14.61873197]\n",
      " [18.08820059]\n",
      " [21.70367583]\n",
      " [36.34229713]\n",
      " [14.8659961 ]\n",
      " [31.49273949]\n",
      " [18.32636502]\n",
      " [20.3618714 ]\n",
      " [27.69693912]\n",
      " [35.29059911]\n",
      " [ 5.80749595]\n",
      " [14.51099779]\n",
      " [28.33349203]\n",
      " [10.8726238 ]\n",
      " [21.09967876]\n",
      " [20.2565236 ]\n",
      " [15.0580598 ]\n",
      " [ 9.43926298]\n",
      " [16.84543954]\n",
      " [20.30015977]\n",
      " [35.25519671]\n",
      " [16.40714722]\n",
      " [ 8.76296789]\n",
      " [24.92051501]\n",
      " [36.74296562]\n",
      " [38.02173501]\n",
      " [37.80140516]\n",
      " [42.56573162]\n",
      " [33.48247673]\n",
      " [20.39370585]\n",
      " [16.17615576]\n",
      " [30.46846243]\n",
      " [16.83558645]\n",
      " [17.69885471]\n",
      " [20.62044409]\n",
      " [19.70136455]\n",
      " [20.58234161]\n",
      " [32.2173158 ]\n",
      " [17.78064279]\n",
      " [25.0609709 ]\n",
      " [20.59988155]\n",
      " [16.92894273]\n",
      " [19.16426525]\n",
      " [20.67540684]\n",
      " [34.64135741]\n",
      " [20.25583015]\n",
      " [24.02783001]\n",
      " [13.44792731]\n",
      " [30.81788797]\n",
      " [15.87698342]\n",
      " [18.42143169]\n",
      " [36.51864809]\n",
      " [32.64247678]\n",
      " [15.85522038]\n",
      " [24.9800797 ]\n",
      " [22.40528885]\n",
      " [ 5.12726366]\n",
      " [19.06211464]\n",
      " [21.66504557]\n",
      " [29.08733575]\n",
      " [19.57223045]\n",
      " [17.45081725]\n",
      " [31.22126974]\n",
      " [15.16497576]\n",
      " [12.73303966]\n",
      " [20.38692302]\n",
      " [24.22091008]\n",
      " [18.00439123]\n",
      " [24.2537897 ]\n",
      " [23.32060241]\n",
      " [19.44517182]\n",
      " [22.2593567 ]\n",
      " [25.17684213]\n",
      " [ 9.73134944]\n",
      " [ 9.10825757]\n",
      " [20.05051353]\n",
      " [ 8.26675929]\n",
      " [18.138389  ]\n",
      " [12.1939476 ]\n",
      " [18.00282363]\n",
      " [26.769419  ]\n",
      " [41.78628393]\n",
      " [20.10167895]\n",
      " [33.64813391]\n",
      " [42.38301989]\n",
      " [22.35011768]\n",
      " [16.63586258]\n",
      " [31.66782249]\n",
      " [15.80768542]\n",
      " [ 7.3165219 ]\n",
      " [38.64450484]\n",
      " [20.84879482]\n",
      " [14.50589244]\n",
      " [23.98950373]\n",
      " [16.85687558]\n",
      " [19.71511227]\n",
      " [14.39085904]\n",
      " [44.00206193]\n",
      " [35.65925256]\n",
      " [29.24894542]\n",
      " [13.57300374]\n",
      " [23.46833064]\n",
      " [27.38289821]\n",
      " [29.68079713]]\n",
      "[[35.74861858]\n",
      " [18.95938213]\n",
      " [13.72928728]\n",
      " [32.55252026]\n",
      " [20.66771501]\n",
      " [13.76028569]\n",
      " [20.90514634]\n",
      " [20.47326062]\n",
      " [14.68081616]\n",
      " [28.44709022]\n",
      " [30.12247   ]\n",
      " [19.03715588]\n",
      " [21.65862139]\n",
      " [20.3624937 ]\n",
      " [15.23680469]\n",
      " [33.47520079]\n",
      " [16.71016697]\n",
      " [32.06820235]\n",
      " [28.13010917]\n",
      " [24.97930663]\n",
      " [32.80939379]\n",
      " [-5.60388575]\n",
      " [20.88155207]\n",
      " [16.97912097]\n",
      " [31.05667596]\n",
      " [38.55629941]\n",
      " [25.1030628 ]\n",
      " [28.5017567 ]\n",
      " [16.06364135]\n",
      " [17.56269644]\n",
      " [25.11859156]\n",
      " [19.99383887]\n",
      " [23.21128804]\n",
      " [22.47273225]\n",
      " [14.52759415]\n",
      " [25.82988428]\n",
      " [ 8.40045417]\n",
      " [21.68868428]\n",
      " [18.05124485]\n",
      " [13.03129148]\n",
      " [21.61644551]\n",
      " [18.26374534]\n",
      " [23.54236171]\n",
      " [36.41154396]\n",
      " [19.14996392]\n",
      " [ 9.68052631]\n",
      " [28.80700731]\n",
      " [26.50440862]\n",
      " [35.79206716]\n",
      " [22.65847804]\n",
      " [19.01479897]\n",
      " [13.29775168]\n",
      " [27.34635746]\n",
      " [13.10229071]\n",
      " [24.02339933]\n",
      " [41.09276791]\n",
      " [-0.28642569]\n",
      " [14.0133431 ]\n",
      " [20.80433501]\n",
      " [40.01216009]\n",
      " [17.27965227]\n",
      " [25.00225259]\n",
      " [22.84818689]\n",
      " [22.88300855]\n",
      " [29.00886464]\n",
      " [28.16226782]\n",
      " [33.81183709]\n",
      " [26.40559383]\n",
      " [15.44963074]\n",
      " [25.76705192]\n",
      " [26.78115063]\n",
      " [33.01799881]\n",
      " [24.7931002 ]\n",
      " [21.09636693]\n",
      " [23.59515107]\n",
      " [19.53842821]\n",
      " [31.94928818]\n",
      " [22.21382818]\n",
      " [32.52861194]\n",
      " [28.60412688]\n",
      " [30.35849629]\n",
      " [ 5.49771125]\n",
      " [33.25951548]\n",
      " [24.36521743]\n",
      " [34.87518436]\n",
      " [32.82031071]\n",
      " [27.51985138]\n",
      " [35.71904553]\n",
      " [26.67970484]\n",
      " [33.78389557]\n",
      " [19.77701559]\n",
      " [36.30941301]\n",
      " [ 8.63215815]\n",
      " [16.91282109]\n",
      " [23.08899565]\n",
      " [19.09913507]\n",
      " [23.85993833]\n",
      " [30.75893242]\n",
      " [20.77905541]\n",
      " [20.67544578]\n",
      " [18.77017175]\n",
      " [31.11222739]]\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "print(pred_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7038469613599883\n",
      "0.5259543460320142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "train_r2 = r2_score(pred_train,y_train)\n",
    "print(train_r2)\n",
    "test_r2 = r2_score(pred_test,y_test)\n",
    "print(test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.526290953326775\n",
      "32.82343088698891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "train_mse = mean_squared_error(pred_train,y_train)\n",
    "print(train_mse)\n",
    "test_mse = mean_squared_error(pred_test,y_test)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.156186975683529\n",
      "3.7869743333243684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "train_mae = mean_absolute_error(pred_train,y_train)\n",
    "print(train_mae)\n",
    "test_mae = mean_absolute_error(pred_test,y_test)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegocaulonga/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/diegocaulonga/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 2 0 0 2 2 2 2 0 1 0 1 2 0 1 2 1 1 1 0 1 2 2 2 0 2 0 2 0 0 1 2 0 1\n",
      " 0 1 1 0 1 2 2 2 1 0 0 0 0 1 2 2 2 2 1 0 0 0 2 0 1 2 1 1 2 1 1 0 0 2 1 1 1\n",
      " 2 0 1 0 0 1 2 2 1 0 0 1 1 1 0 2 2 2 2 0 1 0 2 0 1 1 2 2 2 0 1 0 2 0 0 0 0\n",
      " 1 2 0 0 1 2 1 0 0]\n",
      "[1 1 2 1 0 1 1 2 2 1 0 2 2 2 1 2 0 1 2 1 2 0 0 2 1 2 1 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "pred_train = model1.predict(X_train)\n",
    "print(pred_train)\n",
    "pred_test = model1.predict(X_test)\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_as = accuracy_score(pred_train,y_train)\n",
    "print(train_as)\n",
    "test_as = accuracy_score(pred_test,y_test)\n",
    "print(test_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9739091318038686\n",
      "0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "train_bas = balanced_accuracy_score(pred_train,y_train)\n",
    "print(train_bas)\n",
    "test_bas = balanced_accuracy_score(pred_test,y_test)\n",
    "print(test_bas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751914414414415\n",
      "0.9692307692307692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "train_ps = precision_score(pred_train,y_train,average=\"weighted\")\n",
    "print(train_ps)\n",
    "test_ps = precision_score(pred_test,y_test,average=\"weighted\")\n",
    "print(test_ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "train_rs = recall_score(pred_train,y_train,average=\"weighted\")\n",
    "print(train_rs)\n",
    "test_rs = recall_score(pred_test,y_test,average=\"weighted\")\n",
    "print(test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9749915611814345\n",
      "0.9665396825396826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "train_f1 = f1_score(pred_train,y_train,average=\"weighted\")\n",
    "print(train_f1)\n",
    "test_f1 = f1_score(pred_test,y_test,average=\"weighted\")\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  0  0]\n",
      " [ 0 38  2]\n",
      " [ 0  1 36]]\n",
      "[[ 7  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "train_conf_matrix = confusion_matrix(y_train,pred_train)\n",
    "print(train_conf_matrix)\n",
    "test_conf_matrix = confusion_matrix(y_test,pred_test)\n",
    "print(test_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
